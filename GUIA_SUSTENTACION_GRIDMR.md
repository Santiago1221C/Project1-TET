# GUÃA COMPLETA PARA SUSTENTACIÃ“N DEL PROYECTO GRIDMR

## ğŸ“‹ INFORMACIÃ“N GENERAL DEL PROYECTO

### **Â¿QuÃ© es GridMR?**
GridMR es un sistema distribuido de procesamiento de datos que implementa el patrÃ³n MapReduce en un entorno de Grid Computing. El sistema permite procesar grandes volÃºmenes de datos de manera paralela utilizando mÃºltiples nodos de computaciÃ³n.

### **Arquitectura del Sistema**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLIENTE       â”‚    â”‚     MASTER      â”‚    â”‚    WORKERS      â”‚
â”‚   (Python)      â”‚â—„â”€â”€â–ºâ”‚   (Java/Spring) â”‚â—„â”€â”€â–ºâ”‚    (C++/gRPC)   â”‚
â”‚   REST API      â”‚    â”‚   gRPC + REST   â”‚    â”‚   Map/Reduce    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NFS/EFS       â”‚    â”‚   PERSISTENCIA  â”‚    â”‚   ALMACENAMIENTOâ”‚
â”‚   (Compartido)  â”‚    â”‚   (Estado)      â”‚    â”‚   (Local)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ ESTRUCTURA COMPLETA DEL PROYECTO

### **1. Directorio Principal (`Project1-TET/`)**
```
Project1-TET/
â”œâ”€â”€ gridmr-master/          # Nodo Master (Java/Spring Boot)
â”œâ”€â”€ workers/                # Workers (C++/gRPC)
â”œâ”€â”€ client/                 # Cliente (Python)
â”œâ”€â”€ serv_persistor/         # Servicio de Persistencia (Python)
â”œâ”€â”€ aws-deployment/         # Scripts de despliegue AWS
â”œâ”€â”€ scripts/                # Scripts de configuraciÃ³n
â”œâ”€â”€ nfs_shared/             # Almacenamiento compartido
â””â”€â”€ generated/              # Archivos generados por protobuf
```

### **2. Nodo Master (`gridmr-master/`)**
```
gridmr-master/
â”œâ”€â”€ src/main/java/com/gridmr/master/
â”‚   â”œâ”€â”€ components/         # Componentes principales
â”‚   â”‚   â”œâ”€â”€ ResourceManager.java      # GestiÃ³n de workers
â”‚   â”‚   â”œâ”€â”€ NodeManager.java          # GestiÃ³n de nodos
â”‚   â”‚   â”œâ”€â”€ Scheduler.java            # Programador de tareas
â”‚   â”‚   â”œâ”€â”€ JobManager.java           # GestiÃ³n de trabajos
â”‚   â”‚   â”œâ”€â”€ ChunkManager.java         # GestiÃ³n de chunks
â”‚   â”‚   â”œâ”€â”€ MasterPersistenceManager.java  # Persistencia
â”‚   â”‚   â””â”€â”€ MasterFailoverManager.java     # Tolerancia a fallos
â”‚   â”œâ”€â”€ controller/         # Controladores REST
â”‚   â”‚   â”œâ”€â”€ GridMRRestController.java      # API REST principal
â”‚   â”‚   â””â”€â”€ MasterGrpcController.java      # API gRPC
â”‚   â”œâ”€â”€ grpc/               # Servicios gRPC
â”‚   â”‚   â”œâ”€â”€ MasterGrpcService.java         # Servicio gRPC
â”‚   â”‚   â””â”€â”€ GrpcMessages.java              # Mensajes gRPC
â”‚   â”œâ”€â”€ model/              # Modelos de datos
â”‚   â”‚   â”œâ”€â”€ Worker.java                    # Modelo Worker
â”‚   â”‚   â”œâ”€â”€ NodeInfo.java                  # Modelo Nodo
â”‚   â”‚   â”œâ”€â”€ Job.java                       # Modelo Trabajo
â”‚   â”‚   â”œâ”€â”€ Task.java                      # Modelo Tarea
â”‚   â”‚   â””â”€â”€ [otros modelos...]
â”‚   â”œâ”€â”€ config/             # ConfiguraciÃ³n Spring
â”‚   â”‚   â””â”€â”€ GridMRConfiguration.java       # ConfiguraciÃ³n DI
â”‚   â”œâ”€â”€ GridMRMaster.java           # Clase principal
â”‚   â””â”€â”€ GridMRMasterApplication.java       # AplicaciÃ³n Spring Boot
â”œâ”€â”€ src/main/proto/         # Archivos Protocol Buffers
â”‚   â”œâ”€â”€ master_internal.proto              # Servicio interno
â”‚   â””â”€â”€ worker/                            # Servicios worker
â”œâ”€â”€ pom.xml                 # ConfiguraciÃ³n Maven
â””â”€â”€ README.md               # DocumentaciÃ³n
```

### **3. Workers (`workers/`)**
```
workers/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ worker_main.cpp     # Punto de entrada principal
â”‚   â”œâ”€â”€ worker.cpp          # ImplementaciÃ³n del worker
â”‚   â”œâ”€â”€ map_task.cpp        # Tareas Map
â”‚   â””â”€â”€ reduce_task.cpp     # Tareas Reduce
â”œâ”€â”€ generated/cpp/          # Archivos generados por protobuf
â”œâ”€â”€ Makefile               # CompilaciÃ³n
â””â”€â”€ WorkerServer.cpp       # Servidor gRPC
```

### **4. Cliente (`client/`)**
```
client/
â”œâ”€â”€ client.py              # Cliente principal
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ test_input.txt         # Archivo de prueba
```

---

## ğŸ”§ COMPONENTES PRINCIPALES Y SU FUNCIÃ“N

### **A. NODO MASTER (Java/Spring Boot)**

#### **1. COMPONENTES PRINCIPALES (`components/`)**

##### **1.1 ResourceManager.java** - GestiÃ³n de Workers
- **FunciÃ³n**: Gestiona la vida Ãºtil completa de los workers en el sistema
- **Responsabilidades**:
  - **Registro de Workers**: Registra nuevos workers con sus capacidades (CPU, memoria, disco)
  - **Monitoreo de Heartbeats**: Verifica cada 5 segundos que los workers estÃ©n activos
  - **DetecciÃ³n de Fallos**: Identifica workers inactivos con timeout de 10 segundos
  - **AsignaciÃ³n de Tareas**: Encuentra el mejor worker disponible para cada tarea
  - **Balanceamiento de Carga**: Distribuye tareas segÃºn capacidad y disponibilidad
- **Tolerancia a Fallos**:
  - Timeout de 10 segundos para workers
  - Reintentos automÃ¡ticos (mÃ¡ximo 3 intentos)
  - Health checks proactivos cada 3 segundos
  - ReasignaciÃ³n automÃ¡tica de tareas cuando un worker falla
- **MÃ©todos Clave**:
  - `registerWorker()`: Registra un nuevo worker
  - `findBestAvailableWorker()`: Encuentra el mejor worker para una tarea
  - `assignTaskToWorker()`: Asigna una tarea especÃ­fica
  - `performProactiveHealthChecks()`: Monitoreo proactivo de salud

##### **1.2 NodeManager.java** - GestiÃ³n de Nodos FÃ­sicos
- **FunciÃ³n**: Gestiona los nodos fÃ­sicos (EC2 instances) donde corren los workers
- **Responsabilidades**:
  - **Registro de Nodos**: Registra nodos con sus capacidades y tipos
  - **Balanceamiento de Carga**: Distribuye workers entre nodos disponibles
  - **Health Checks**: Monitorea la salud de los nodos cada 5 segundos
  - **Descubrimiento AutomÃ¡tico**: Detecta nodos que se unen o salen del sistema
  - **AsignaciÃ³n Ã“ptima**: Encuentra el mejor nodo para asignar un worker
- **Tolerancia a Fallos**:
  - Timeout de 30 segundos para nodos
  - Reintentos automÃ¡ticos (mÃ¡ximo 3 intentos)
  - MigraciÃ³n automÃ¡tica de workers a otros nodos
  - Limpieza automÃ¡tica de nodos inactivos
- **MÃ©todos Clave**:
  - `registerNode()`: Registra un nuevo nodo
  - `findBestNodeForWorker()`: Encuentra el mejor nodo para un worker
  - `calculateNodeScore()`: Calcula score de prioridad para balanceamiento
  - `performNodeHealthChecks()`: Monitoreo de salud de nodos

##### **1.3 Scheduler.java** - Programador de Tareas
- **FunciÃ³n**: Programa y distribuye tareas Map y Reduce a workers disponibles
- **Responsabilidades**:
  - **GestiÃ³n de Colas**: Mantiene colas separadas para tareas Map y Reduce
  - **AsignaciÃ³n Inteligente**: Asigna tareas segÃºn prioridad y disponibilidad
  - **Monitoreo de Progreso**: Rastrea el estado de todas las tareas asignadas
  - **ReasignaciÃ³n**: Reasigna tareas cuando un worker falla o excede timeout
  - **GestiÃ³n de Timeouts**: Detecta tareas que exceden su tiempo lÃ­mite
- **CaracterÃ­sticas**:
  - Colas separadas para Map y Reduce (Map tiene prioridad)
  - Timeout de 5 minutos por tarea
  - ReasignaciÃ³n automÃ¡tica en caso de fallos
  - EstadÃ­sticas detalladas de rendimiento
- **MÃ©todos Clave**:
  - `addTask()`: Agrega una tarea a la cola correspondiente
  - `schedulePendingTasks()`: Asigna tareas pendientes automÃ¡ticamente
  - `reassignTask()`: Reasigna una tarea a un nuevo worker
  - `checkTaskTimeouts()`: Verifica tareas que excedieron su timeout

##### **1.4 JobManager.java** - GestiÃ³n de Trabajos MapReduce
- **FunciÃ³n**: Gestiona el ciclo de vida completo de los trabajos MapReduce
- **Responsabilidades**:
  - **CreaciÃ³n de Trabajos**: Crea trabajos con archivos de entrada y configuraciÃ³n
  - **DivisiÃ³n en Tareas**: Divide trabajos en tareas Map y Reduce
  - **Monitoreo de Fases**: Rastrea el progreso de las fases Map y Reduce
  - **GestiÃ³n de Dependencias**: Asegura que Reduce solo inicie cuando Map termine
  - **FinalizaciÃ³n**: Marca trabajos como completados o fallidos
- **Flujo de Trabajo**:
  1. Recibe trabajo del cliente
  2. Crea tareas Map para cada archivo de entrada
  3. EnvÃ­a tareas Map al Scheduler
  4. Monitorea progreso de fase Map
  5. Cuando Map termina, crea tareas Reduce
  6. Monitorea progreso de fase Reduce
  7. Marca trabajo como completado
- **MÃ©todos Clave**:
  - `submitJob()`: EnvÃ­a un nuevo trabajo al sistema
  - `createAndSubmitMapTasks()`: Crea y envÃ­a tareas Map
  - `createAndSubmitReduceTasks()`: Crea y envÃ­a tareas Reduce
  - `checkJobProgress()`: Monitorea el progreso del trabajo

##### **1.5 ChunkManager.java** - GestiÃ³n de Fragmentos de Datos
- **FunciÃ³n**: Gestiona la divisiÃ³n y transferencia de datos en fragmentos (chunks)
- **Responsabilidades**:
  - **DivisiÃ³n de Archivos**: Divide archivos grandes en chunks manejables
  - **Almacenamiento**: Almacena chunks en disco y memoria
  - **Transferencia**: Transfiere chunks a workers para procesamiento
  - **GestiÃ³n de Resultados**: Almacena resultados intermedios y finales
  - **Limpieza**: Limpia chunks antiguos automÃ¡ticamente
- **CaracterÃ­sticas**:
  - Chunks de 64MB por defecto
  - Almacenamiento hÃ­brido (disco + memoria)
  - Transferencia asÃ­ncrona a workers
  - RetenciÃ³n de 24 horas para chunks
  - LÃ­mite de 10GB de almacenamiento
- **MÃ©todos Clave**:
  - `createChunksFromFile()`: Divide un archivo en chunks
  - `transferChunkToWorker()`: Transfiere chunk a un worker
  - `storeIntermediateResult()`: Almacena resultado intermedio
  - `getIntermediateResults()`: Obtiene resultados para fase Reduce

##### **1.6 MasterPersistenceManager.java** - Persistencia del Estado
- **FunciÃ³n**: Persiste el estado del master para recuperaciÃ³n ante fallos
- **Responsabilidades**:
  - **Guardado AutomÃ¡tico**: Guarda estado cada 30 segundos
  - **RecuperaciÃ³n**: Restaura estado desde archivo al reiniciar
  - **Backups**: Crea copias de seguridad del estado
  - **SincronizaciÃ³n**: Mantiene estado consistente entre masters
- **Datos Persistidos**:
  - Lista de workers registrados
  - Lista de nodos activos
  - Trabajos en progreso
  - Tareas asignadas
  - ConfiguraciÃ³n del sistema

##### **1.7 MasterFailoverManager.java** - Tolerancia a Fallos del Master
- **FunciÃ³n**: Gestiona la alta disponibilidad del master
- **Responsabilidades**:
  - **ElecciÃ³n de LÃ­der**: Implementa algoritmo de elecciÃ³n de lÃ­der
  - **SincronizaciÃ³n**: Sincroniza estado entre mÃºltiples masters
  - **Failover**: Cambia automÃ¡ticamente a master de respaldo
  - **RecuperaciÃ³n**: Restaura operaciÃ³n normal tras fallos
- **CaracterÃ­sticas**:
  - MÃºltiples masters pueden coexistir
  - Solo un master es lÃ­der a la vez
  - Failover automÃ¡tico en caso de fallo del lÃ­der
  - SincronizaciÃ³n de estado en tiempo real

#### **2. MODELOS DE DATOS (`model/`)**

##### **2.1 Worker.java** - Modelo de Worker
- **FunciÃ³n**: Representa un worker individual en el sistema
- **Propiedades**:
  - **IdentificaciÃ³n**: `workerId`, `host`, `port`
  - **Capacidad**: `cpuCores`, `memoryMB`, `diskSpaceGB`, `computePower`
  - **Estado**: `status`, `currentLoad`, `maxConcurrentTasks`
  - **Metadatos**: `registeredAt`, `lastHeartbeat`, `lastTaskUpdate`
  - **EstadÃ­sticas**: `completedTasks`, `failedTasks`, `totalExecutionTimeMs`
- **MÃ©todos Clave**:
  - `isAvailable()`: Verifica si puede recibir tareas
  - `getPriorityScore()`: Calcula score para asignaciÃ³n de tareas
  - `assignTask()`: Asigna una tarea al worker
  - `isActive()`: Verifica si estÃ¡ respondiendo heartbeats

##### **2.2 Job.java** - Modelo de Trabajo MapReduce
- **FunciÃ³n**: Representa un trabajo MapReduce completo
- **Propiedades**:
  - **IdentificaciÃ³n**: `jobId`, `clientId`
  - **Estado**: `status`, `createdAt`, `startedAt`, `completedAt`
  - **Datos**: `inputFiles`, `outputDirectory`
  - **ConfiguraciÃ³n**: `numMappers`, `numReducers`, `mapFunction`, `reduceFunction`
  - **Tareas**: `mapTasks`, `reduceTasks`
  - **Resultados**: `intermediateResults`, `finalResults`
- **MÃ©todos Clave**:
  - `isCompleted()`: Verifica si el trabajo terminÃ³
  - `areMapTasksCompleted()`: Verifica si fase Map terminÃ³
  - `areReduceTasksCompleted()`: Verifica si fase Reduce terminÃ³

##### **2.3 Task.java** - Modelo de Tarea Individual
- **FunciÃ³n**: Representa una tarea Map o Reduce individual
- **Propiedades**:
  - **IdentificaciÃ³n**: `taskId`, `jobId`, `workerId`
  - **Tipo**: `type` (MAP o REDUCE)
  - **Estado**: `status`, `createdAt`, `startedAt`, `completedAt`
  - **Datos**: `inputData`, `outputData`, `errorMessage`
  - **ConfiguraciÃ³n**: `functionCode`, `priority`
- **MÃ©todos Clave**:
  - `isMapTask()`: Verifica si es tarea Map
  - `isReduceTask()`: Verifica si es tarea Reduce
  - `start()`: Marca tarea como iniciada
  - `complete()`: Marca tarea como completada

##### **2.4 DataChunk.java** - Modelo de Fragmento de Datos
- **FunciÃ³n**: Representa un fragmento de datos para procesamiento
- **Propiedades**:
  - **IdentificaciÃ³n**: `chunkId`, `jobId`, `originalFileName`
  - **UbicaciÃ³n**: `startOffset`, `endOffset`, `sizeBytes`
  - **Estado**: `location`, `assignedWorkerId`, `isProcessed`
  - **Metadatos**: `createdAt`, `assignedAt`, `processedAt`
- **MÃ©todos Clave**:
  - `isAssigned()`: Verifica si estÃ¡ asignado a un worker
  - `isAvailable()`: Verifica si estÃ¡ disponible para asignaciÃ³n
  - `getRangeHeader()`: Obtiene header HTTP Range para transferencia

##### **2.5 NodeInfo.java** - Modelo de Nodo FÃ­sico
- **FunciÃ³n**: Representa un nodo fÃ­sico en el sistema
- **Propiedades**:
  - **IdentificaciÃ³n**: `nodeId`, `host`, `port`, `nodeType`
  - **Capacidad**: `maxWorkers`, `currentWorkers`, `cpuCores`, `memoryGB`
  - **Estado**: `status`, `registeredAt`, `lastHeartbeat`
  - **EstadÃ­sticas**: `totalWorkersAssigned`, `totalTasksCompleted`
- **MÃ©todos Clave**:
  - `hasCapacity()`: Verifica si puede recibir mÃ¡s workers
  - `getPriorityScore()`: Calcula score para asignaciÃ³n de workers
  - `assignWorker()`: Asigna un worker al nodo

##### **2.6 Enums de Estado**
- **WorkerStatus**: `REGISTERED`, `READY`, `BUSY`, `OFFLINE`, `FAILED`
- **JobStatus**: `PENDING`, `MAP_PHASE`, `REDUCE_PHASE`, `COMPLETED`, `FAILED`, `CANCELLED`
- **TaskStatus**: `PENDING`, `ASSIGNED`, `RUNNING`, `COMPLETED`, `FAILED`, `CANCELLED`
- **TaskType**: `MAP`, `REDUCE`
- **NodeStatus**: `REGISTERED`, `ACTIVE`, `BUSY`, `OFFLINE`, `MAINTENANCE`, `ERROR`, `UNREGISTERED`

#### **3. IMPORTANCIA DE CADA ARCHIVO EN LA IMPLEMENTACIÃ“N**

##### **3.1 Archivos CrÃ­ticos para Grid Computing**
- **ResourceManager.java**: **CRÃTICO** - Sin este archivo no hay Grid Computing. Gestiona la distribuciÃ³n de workers y tareas.
- **NodeManager.java**: **CRÃTICO** - Esencial para Grid Computing. Gestiona nodos fÃ­sicos y balanceamiento de carga.
- **Scheduler.java**: **CRÃTICO** - Core del Grid Computing. Distribuye tareas entre workers disponibles.
- **ChunkManager.java**: **CRÃTICO** - Fundamental para procesamiento distribuido. Divide datos en chunks para procesamiento paralelo.

##### **3.2 Archivos CrÃ­ticos para MapReduce**
- **JobManager.java**: **CRÃTICO** - Implementa el patrÃ³n MapReduce completo. Sin este no hay MapReduce.
- **Task.java**: **CRÃTICO** - Representa las tareas Map y Reduce individuales.
- **Job.java**: **CRÃTICO** - Representa un trabajo MapReduce completo con sus fases.
- **DataChunk.java**: **CRÃTICO** - Permite dividir datos para procesamiento Map paralelo.

##### **3.3 Archivos de Tolerancia a Fallos**
- **MasterPersistenceManager.java**: **IMPORTANTE** - Permite recuperaciÃ³n ante fallos del master.
- **MasterFailoverManager.java**: **IMPORTANTE** - Implementa alta disponibilidad del master.
- **Worker.java**: **IMPORTANTE** - Incluye lÃ³gica de health checks y disponibilidad.

##### **3.4 Archivos de Modelado**
- **NodeInfo.java**: **IMPORTANTE** - Modela nodos fÃ­sicos para Grid Computing.
- **Enums**: **NECESARIOS** - Definen estados y tipos para el sistema.

##### **3.5 Flujo de Dependencias**
```
Cliente â†’ JobManager â†’ Scheduler â†’ ResourceManager â†’ Workers
    â†“         â†“           â†“            â†“
Job.java â†’ Task.java â†’ Worker.java â†’ DataChunk.java
    â†“         â†“           â†“            â†“
NodeManager â† ChunkManager â† Scheduler â† JobManager
```

##### **3.6 Evidencia de Grid Computing en los Archivos**
1. **ResourceManager**: Distribuye workers en mÃºltiples nodos
2. **NodeManager**: Gestiona nodos fÃ­sicos distribuidos
3. **Scheduler**: Asigna tareas a workers en diferentes nodos
4. **ChunkManager**: Divide datos para procesamiento paralelo
5. **Worker**: Representa unidades de cÃ³mputo distribuidas

##### **3.7 Evidencia de MapReduce en los Archivos**
1. **JobManager**: Implementa fases Map y Reduce secuenciales
2. **Task**: Distingue entre tareas Map y Reduce
3. **Job**: Contiene tareas Map y Reduce separadas
4. **DataChunk**: Permite procesamiento Map paralelo
5. **Scheduler**: Prioriza tareas Map sobre Reduce

### **B. WORKERS (C++)**

#### **1. worker_main.cpp**
- **FunciÃ³n**: Punto de entrada del worker
- **Responsabilidades**:
  - InicializaciÃ³n del servidor gRPC
  - ConfiguraciÃ³n de puertos y NFS
  - Manejo de argumentos de lÃ­nea de comandos

#### **2. worker.cpp**
- **FunciÃ³n**: ImplementaciÃ³n del worker
- **Responsabilidades**:
  - EjecuciÃ³n de tareas Map
  - EjecuciÃ³n de tareas Reduce
  - ComunicaciÃ³n con el master
  - Procesamiento de archivos

### **C. CLIENTE (Python)**

#### **1. client.py**
- **FunciÃ³n**: Interfaz de usuario del sistema
- **Responsabilidades**:
  - Subida de archivos al NFS
  - EnvÃ­o de trabajos al master
  - Monitoreo del progreso
  - Descarga de resultados

---

## ğŸŒ COMUNICACIÃ“N ENTRE COMPONENTES

### **1. Cliente â†” Master (REST API)**
- **Protocolo**: HTTP/HTTPS
- **Formato**: JSON
- **Endpoints principales**:
  - `POST /api/jobs/submit` - Enviar trabajo
  - `GET /api/jobs/{id}/status` - Estado del trabajo
  - `GET /api/workers` - Listar workers
  - `GET /api/health` - Health check

### **2. Master â†” Workers (gRPC)**
- **Protocolo**: gRPC sobre HTTP/2
- **Formato**: Protocol Buffers
- **Servicios**:
  - `RegisterWorker` - Registro de worker
  - `Heartbeat` - Latido de vida
  - `ExecuteMapTask` - Ejecutar tarea Map
  - `ExecuteReduceTask` - Ejecutar tarea Reduce

### **3. Workers â†” NFS (Sistema de archivos)**
- **Protocolo**: NFS/EFS
- **Uso**: Almacenamiento compartido de datos
- **Directorios**:
  - `/input/` - Archivos de entrada
  - `/intermediate/` - Resultados intermedios
  - `/output/` - Resultados finales

## ğŸ”§ Â¿POR QUÃ‰ REST PARA CLIENTE-MASTER Y gRPC PARA MASTER-WORKERS?

### **1. REST API: Cliente â†” Master**

#### **1.1 Â¿Por quÃ© REST para el Cliente?**
- **Simplicidad**: REST es fÃ¡cil de entender y usar para desarrolladores
- **EstÃ¡ndar Web**: HTTP es universalmente soportado
- **Herramientas**: Muchas herramientas (Postman, curl, navegadores) soportan REST
- **Caching**: HTTP permite caching para mejorar rendimiento
- **Stateless**: Cada request es independiente, fÃ¡cil de escalar

#### **1.2 CaracterÃ­sticas del Cliente**
- **InteracciÃ³n Humana**: El cliente es usado por humanos, no por mÃ¡quinas
- **Frecuencia Baja**: No necesita comunicaciÃ³n constante como los workers
- **Datos Simples**: EnvÃ­a configuraciones y recibe estados, no datos masivos
- **Debugging**: FÃ¡cil de debuggear con herramientas web estÃ¡ndar

#### **1.3 Endpoints REST Implementados**
```http
POST /api/jobs/submit          # Enviar trabajo
GET  /api/jobs/{id}/status     # Estado del trabajo
GET  /api/workers              # Listar workers
GET  /api/health               # Health check
GET  /api/nodes                # Listar nodos
POST /api/workers/register     # Registrar worker
```

### **2. gRPC: Master â†” Workers**

#### **2.1 Â¿Por quÃ© gRPC para Workers?**
- **Alto Rendimiento**: Workers necesitan comunicaciÃ³n eficiente
- **Frecuencia Alta**: Heartbeats cada 5 segundos, asignaciÃ³n constante de tareas
- **Datos Binarios**: Transferencia de chunks de datos grandes
- **Tipado Fuerte**: Workers son mÃ¡quinas, necesitan contratos claros
- **Streaming**: Monitoreo en tiempo real del progreso

#### **2.2 CaracterÃ­sticas de los Workers**
- **ComunicaciÃ³n Constante**: Heartbeats, reportes de progreso, asignaciÃ³n de tareas
- **Datos Masivos**: Transferencia de chunks de datos
- **AutomatizaciÃ³n**: Los workers son procesos automatizados
- **Rendimiento CrÃ­tico**: La eficiencia es crucial para el Grid Computing

### **3. ComparaciÃ³n de Arquitecturas**

#### **3.1 REST vs gRPC - CuÃ¡ndo Usar Cada Uno**

| Aspecto | REST (Cliente-Master) | gRPC (Master-Workers) |
|---------|----------------------|----------------------|
| **Frecuencia** | Baja (interacciÃ³n humana) | Alta (heartbeats, tareas) |
| **Datos** | JSON (configuraciones) | Binary (chunks, streams) |
| **Usuarios** | Humanos (desarrolladores) | MÃ¡quinas (workers) |
| **Debugging** | FÃ¡cil (herramientas web) | Complejo (herramientas especializadas) |
| **Rendimiento** | Suficiente | CrÃ­tico |
| **Caching** | Importante | No relevante |
| **Streaming** | No necesario | Esencial |

#### **3.2 Flujo de ComunicaciÃ³n en GridMR**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    REST API     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    gRPC      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Master   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Workers   â”‚
â”‚  (Python)   â”‚   HTTP/JSON    â”‚   (Java)    â”‚  HTTP/2/PB  â”‚   (C++)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚                              â”‚
     â”‚ 1. Enviar trabajo            â”‚ 2. Asignar tareas            â”‚ 3. Procesar
     â”‚ 2. Consultar estado          â”‚ 3. Monitorear progreso       â”‚ 4. Reportar
     â”‚ 3. Descargar resultados      â”‚ 4. Gestionar fallos          â”‚ 5. Heartbeat
```

### **4. Ventajas de gRPC para Grid Computing**

#### **4.1 Alto Rendimiento**
- **HTTP/2**: MultiplexaciÃ³n de conexiones, reduce latencia
- **SerializaciÃ³n Binaria**: Protocol Buffers es mÃ¡s eficiente que JSON
- **Streaming**: Permite transferencia de datos en tiempo real
- **CompresiÃ³n**: Reduce ancho de banda para transferencias de chunks

#### **4.2 ComunicaciÃ³n Bidireccional**
- **Heartbeats**: Workers pueden enviar latidos de vida continuamente
- **Notificaciones**: Master puede notificar cambios de estado instantÃ¡neamente
- **Streaming**: Permite monitoreo en tiempo real del progreso de tareas

#### **4.3 Tipado Fuerte**
- **Protocol Buffers**: Define contratos claros entre Master y Workers
- **ValidaciÃ³n AutomÃ¡tica**: Los datos se validan automÃ¡ticamente
- **Compatibilidad**: Versiones diferentes pueden coexistir

#### **4.4 Escalabilidad**
- **Conexiones Persistentes**: Reduce overhead de conexiones
- **Balanceamiento**: gRPC soporta load balancing nativo
- **MultiplexaciÃ³n**: Una conexiÃ³n puede manejar mÃºltiples requests

### **5. Ventajas de REST para Cliente**

#### **5.1 Simplicidad y Usabilidad**
- **FÃ¡cil de Usar**: Cualquier desarrollador puede usar REST
- **Herramientas**: Postman, curl, navegadores web
- **DocumentaciÃ³n**: Swagger/OpenAPI para documentaciÃ³n automÃ¡tica
- **Debugging**: FÃ¡cil de debuggear con herramientas web

#### **5.2 EstÃ¡ndares Web**
- **HTTP**: Protocolo estÃ¡ndar de la web
- **JSON**: Formato de datos universalmente soportado
- **Caching**: HTTP permite caching para mejorar rendimiento
- **Proxies**: Funciona a travÃ©s de proxies y firewalls

#### **5.3 Flexibilidad**
- **Stateless**: Cada request es independiente
- **Escalabilidad**: FÃ¡cil de escalar horizontalmente
- **Versionado**: FÃ¡cil de versionar APIs
- **IntegraciÃ³n**: FÃ¡cil integraciÃ³n con otros sistemas

### **6. ImplementaciÃ³n EspecÃ­fica en GridMR**

#### **6.1 REST API - Cliente a Master**
```java
@RestController
@RequestMapping("/api")
public class GridMRRestController {
    @PostMapping("/jobs/submit")
    public ResponseEntity<JobResponse> submitJob(@RequestBody JobRequest request);
    
    @GetMapping("/jobs/{id}/status")
    public ResponseEntity<JobStatus> getJobStatus(@PathVariable String id);
    
    @GetMapping("/workers")
    public ResponseEntity<List<Worker>> getWorkers();
}
```

#### **6.2 gRPC - Master a Workers**
```protobuf
service MasterInternalService {
  rpc RegisterWorker(WorkerRegistrationRequest) returns (WorkerRegistrationResponse);
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
  rpc ExecuteMapTask(MapTaskRequest) returns (MapTaskResponse);
  rpc ExecuteReduceTask(ReduceTaskRequest) returns (ReduceTaskResponse);
}
```

### **7. Evidencia de la DecisiÃ³n ArquitectÃ³nica**

#### **7.1 REST para Cliente - Evidencia**
- **Interfaz Humana**: El cliente es usado por desarrolladores
- **Frecuencia Baja**: No necesita comunicaciÃ³n constante
- **Simplicidad**: FÃ¡cil de implementar y mantener
- **EstÃ¡ndares**: Usa protocolos web estÃ¡ndar

#### **7.2 gRPC para Workers - Evidencia**
- **Alto Rendimiento**: Workers necesitan comunicaciÃ³n eficiente
- **Frecuencia Alta**: Heartbeats cada 5 segundos
- **Datos Binarios**: Transferencia de chunks grandes
- **AutomatizaciÃ³n**: Workers son procesos automatizados

### **8. Beneficios de la Arquitectura HÃ­brida**

#### **8.1 Lo Mejor de Ambos Mundos**
- **REST**: Simplicidad para el cliente
- **gRPC**: Rendimiento para workers
- **Flexibilidad**: Cada componente usa la tecnologÃ­a mÃ¡s apropiada
- **Mantenibilidad**: FÃ¡cil de mantener y extender

#### **8.2 Escalabilidad**
- **Cliente**: REST escala horizontalmente
- **Workers**: gRPC maneja mÃºltiples workers eficientemente
- **Master**: Puede manejar ambos tipos de comunicaciÃ³n

#### **8.3 Tolerancia a Fallos**
- **REST**: HTTP tiene retry logic incorporado
- **gRPC**: ReconexiÃ³n automÃ¡tica y retry logic
- **HÃ­brido**: Tolerancia a fallos en ambos niveles

---

## ğŸš€ PROCESO DE EJECUCIÃ“N COMPLETO

### **1. InicializaciÃ³n del Sistema**
```bash
# 1. Iniciar Master
cd gridmr-master
mvn spring-boot:run

# 2. Iniciar Workers
cd workers
make
./worker worker-001 9090 /mnt/gridmr_nfs
./worker worker-002 9091 /mnt/gridmr_nfs

# 3. Ejecutar Cliente
cd client
python client.py --create-sample --job-type wordcount
```

### **2. Flujo de un Trabajo MapReduce**

#### **Fase 1: PreparaciÃ³n**
1. Cliente sube archivo al NFS
2. Cliente envÃ­a trabajo al Master via REST
3. Master valida el trabajo y crea Job
4. Master divide el trabajo en tareas Map

#### **Fase 2: EjecuciÃ³n Map**
1. Master asigna tareas Map a workers disponibles
2. Workers procesan chunks de datos en paralelo
3. Workers guardan resultados intermedios en NFS
4. Workers notifican completaciÃ³n al Master

#### **Fase 3: EjecuciÃ³n Reduce**
1. Master agrupa resultados intermedios por clave
2. Master asigna tareas Reduce a workers
3. Workers procesan grupos de datos intermedios
4. Workers generan resultados finales

#### **Fase 4: FinalizaciÃ³n**
1. Master consolida resultados finales
2. Master notifica completaciÃ³n al Cliente
3. Cliente descarga resultados del NFS

---

## ğŸ›¡ï¸ TOLERANCIA A FALLOS IMPLEMENTADA

### **1. Tolerancia a Fallos de Workers**
- **DetecciÃ³n**: Heartbeats cada 5 segundos
- **Timeout**: 10 segundos sin respuesta
- **RecuperaciÃ³n**: Reintentos automÃ¡ticos (mÃ¡ximo 3)
- **ReasignaciÃ³n**: Tareas se reasignan a otros workers

### **2. Tolerancia a Fallos de Nodos**
- **DetecciÃ³n**: Health checks cada 3 segundos
- **Timeout**: 30 segundos sin respuesta
- **RecuperaciÃ³n**: MigraciÃ³n de workers a otros nodos
- **Balanceamiento**: DistribuciÃ³n automÃ¡tica de carga

### **3. Tolerancia a Fallos del Master**
- **Persistencia**: Estado guardado cada 30 segundos
- **Failover**: ElecciÃ³n automÃ¡tica de nuevo lÃ­der
- **RecuperaciÃ³n**: RestauraciÃ³n del estado desde backup
- **SincronizaciÃ³n**: Estado compartido entre masters

---

## ğŸ“Š EVIDENCIA DE GRID COMPUTING

### **1. DistribuciÃ³n de Carga**
- MÃºltiples nodos procesando en paralelo
- Balanceamiento automÃ¡tico de tareas
- Escalabilidad horizontal

### **2. Procesamiento Paralelo**
- Tareas Map ejecutÃ¡ndose simultÃ¡neamente
- Tareas Reduce procesando grupos en paralelo
- OptimizaciÃ³n de recursos disponibles

### **3. Almacenamiento Distribuido**
- NFS compartido entre todos los nodos
- Acceso concurrente a datos
- Persistencia distribuida

---

## ğŸ”„ EVIDENCIA DE MAP REDUCE

### **1. Fase Map**
```cpp
// En worker.cpp - execute_wordcount_map()
void execute_wordcount_map(const std::string& task_id, const std::string& input_file) {
    std::map<std::string, int> word_count;
    // Procesar chunk de datos
    while (std::getline(file, line)) {
        std::istringstream iss(line);
        while (iss >> word) {
            word_count[word]++;  // MAP: contar palabras
        }
    }
    // Guardar resultado intermedio
    for (const auto& pair : word_count) {
        output << pair.first << "\t" << pair.second << std::endl;
    }
}
```

### **2. Fase Reduce**
```cpp
// En worker.cpp - execute_wordcount_reduce()
void execute_wordcount_reduce(const std::string& task_id, 
                             const std::vector<std::string>& input_files,
                             const std::string& output_file) {
    std::map<std::string, int> final_count;
    // Procesar todos los archivos intermedios
    for (const std::string& file : input_files) {
        while (input >> word >> count) {
            final_count[word] += count;  // REDUCE: sumar conteos
        }
    }
    // Guardar resultado final
    for (const auto& pair : final_count) {
        output << pair.first << "\t" << pair.second << std::endl;
    }
}
```

---

## ğŸ¯ COMANDOS DE VALIDACIÃ“N

### **1. Script de ValidaciÃ³n Completa**
```powershell
# Ejecutar validaciÃ³n completa
.\validacion_sistema.ps1
```

### **2. Comandos Individuales**
```bash
# 1. Health Check
curl http://localhost:8080/api/health

# 2. Listar Workers
curl http://localhost:8080/api/workers

# 3. Listar Nodos
curl http://localhost:8080/api/nodes

# 4. Estado de Persistencia
curl http://localhost:8080/api/persistence/status

# 5. Estado de Failover
curl http://localhost:8080/api/failover/status

# 6. EstadÃ­sticas de Tolerancia a Fallos
curl http://localhost:8080/api/fault-tolerance/text
```

---

## ğŸ“ˆ MÃ‰TRICAS Y MONITOREO

### **1. MÃ©tricas del Sistema**
- Workers activos/inactivos
- Nodos disponibles
- Tareas completadas/fallidas
- Tiempo de ejecuciÃ³n
- Uso de recursos

### **2. Logs y Debugging**
- Logs del Master (Spring Boot)
- Logs de Workers (C++)
- Logs del Cliente (Python)
- Trazas de gRPC
- MÃ©tricas de tolerancia a fallos

---

## ğŸ”§ CONFIGURACIÃ“N Y DESPLIEGUE

### **1. Variables de Entorno**
```bash
# Master
GRIDMR_MASTER_HOST=localhost
GRIDMR_MASTER_PORT=8080

# NFS
GRIDMR_NFS_PATH=/mnt/gridmr_nfs

# Workers
GRIDMR_WORKER_PORT=9090
GRIDMR_WORKER_ID=worker-001
```

### **2. Scripts de Despliegue**
- `scripts/start_system.ps1` - Iniciar sistema completo
- `aws-deployment/` - Scripts para AWS
- `build.bat` - CompilaciÃ³n del proyecto

---

## ğŸ“ PUNTOS CLAVE PARA LA SUSTENTACIÃ“N

### **1. Arquitectura Distribuida**
- SeparaciÃ³n clara de responsabilidades
- ComunicaciÃ³n asÃ­ncrona entre componentes
- Escalabilidad horizontal

### **2. Tolerancia a Fallos**
- MÃºltiples niveles de redundancia
- RecuperaciÃ³n automÃ¡tica
- Persistencia de estado

### **3. Procesamiento Paralelo**
- ImplementaciÃ³n real de MapReduce
- DistribuciÃ³n eficiente de tareas
- OptimizaciÃ³n de recursos

### **4. TecnologÃ­as Modernas**
- gRPC para comunicaciÃ³n de alto rendimiento
- Spring Boot para microservicios
- Protocol Buffers para serializaciÃ³n eficiente
- NFS/EFS para almacenamiento distribuido

### **5. Monitoreo y Observabilidad**
- Health checks proactivos
- MÃ©tricas en tiempo real
- Logs estructurados
- ValidaciÃ³n automÃ¡tica

---

## ğŸ“ NOTAS ADICIONALES

### **1. Dependencias del Proyecto**
- Java 17+ (Master)
- C++17+ (Workers)
- Python 3.12+ (Cliente)
- Maven 3.6+ (Build)
- gRPC 1.58.0
- Spring Boot 3.2.12

### **2. Requisitos del Sistema**
- Sistema operativo: Windows/Linux
- Memoria: MÃ­nimo 4GB RAM
- Almacenamiento: 10GB libres
- Red: Conectividad entre nodos

### **3. Limitaciones Conocidas**
- MÃ¡ximo 100 workers por nodo
- TamaÃ±o mÃ¡ximo de archivo: 1GB
- Timeout de trabajos: 30 minutos
- Reintentos mÃ¡ximos: 3 por componente

---

## ğŸš€ DEMOSTRACIÃ“N EN VIVO

### **1. PreparaciÃ³n**
1. Mostrar estructura del proyecto
2. Explicar arquitectura general
3. Describir tecnologÃ­as utilizadas

### **2. EjecuciÃ³n**
1. Iniciar Master
2. Iniciar Workers
3. Ejecutar Cliente con trabajo de prueba
4. Mostrar monitoreo en tiempo real

### **3. Tolerancia a Fallos**
1. Simular fallo de worker
2. Mostrar recuperaciÃ³n automÃ¡tica
3. Demostrar reasignaciÃ³n de tareas

### **4. ValidaciÃ³n**
1. Ejecutar script de validaciÃ³n
2. Mostrar mÃ©tricas del sistema
3. Verificar resultados del procesamiento

---

**Â¡Esta guÃ­a te proporciona toda la informaciÃ³n necesaria para una sustentaciÃ³n exitosa del proyecto GridMR!**
